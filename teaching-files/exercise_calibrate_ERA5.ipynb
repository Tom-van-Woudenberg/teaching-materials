{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBV model BMI calibration exercise with ERA5 forcing and GRDC observation\n",
    "\n",
    "In this notebook you will calibrate your own HBV model using ERA5 forcing data and GRDC observation data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For forcing we use the eWaterCycle generic forcing generator. This can generate forcing data with ESMValTool from ERA5 data (if available on your machine), as well as CMIP6 data (which will be downloaded automatically). \n",
    "\n",
    "Here we use ERA5 and compare it to the observations of the GRDC for the Rhine basin. In the first cell we load all required dependencies and set a few parameters for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ewatercycle2/lib/python3.10/site-packages/esmvalcore/experimental/_warnings.py:13: UserWarning: \n",
      "  Thank you for trying out the new ESMValCore API.\n",
      "  Note that this API is experimental and may be subject to change.\n",
      "  More info: https://github.com/ESMValGroup/ESMValCore/issues/498\n"
     ]
    }
   ],
   "source": [
    "#from leakybucket.leakybucket_bmi import LeakyBucketBmi\n",
    "import ewatercycle.forcing\n",
    "import ewatercycle.observation.grdc\n",
    "import ewatercycle.analysis\n",
    "from pathlib import Path\n",
    "from cartopy.io import shapereader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "#shapefile that describes the basin we want to study.\n",
    "shapeFile = Path(ewatercycle.__file__).parent / \"testing/data/Rhine/Rhine.shp\"\n",
    "\n",
    "\n",
    "#GRDC station ID for the observation station\n",
    "grdc_station_id = \"6335020\"  # GRDC station ID\n",
    "basin_name = \"Rhine\"\n",
    "\n",
    "#period of interest. Make sure that ERA5 is available on your machine for this period.\n",
    "experiment_start_time=\"2000-01-01T00:00:00Z\"\n",
    "experiment_end_time=\"2000-12-31T00:00:00Z\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forcing is created using the GenericLumpedForcing in eWaterCycle. This selects rainfall and precipitation from the indicated dataset for the given time period and averages over the indicated shape. The result is two NetCDF files and a yaml file. This can later be loaded using ```GenericLumpedForcing.load()```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA5_forcing = ewatercycle.forcing.sources[\"LumpedMakkinkForcing\"].generate(\n",
    "#     dataset=\"ERA5\",\n",
    "#     start_time=experiment_start_time,\n",
    "#     end_time=experiment_end_time,\n",
    "#     shape=shapeFile.absolute(),\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_forcing = ewatercycle.forcing.sources[\"LumpedMakkinkForcing\"].load(\"/home/rhut/repos/teaching-materials/teaching-files/esmvaltool_output/ewcrep_y7z06a2_20240326_125503/work/diagnostic/script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the forcing data available we can prepare the configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e8f254e3dd78daa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "s_0 = np.array([0,  100,  0,  5])\n",
    "p_min_initial= np.array([0,   0.2,  40,    .5,   .001,   1,     .01,  .0001])\n",
    "p_max_initial = np.array([8,    1,  800,   4,    .3,     10,    .1,   .01])\n",
    "p_names = [\"$I_{max}$\",  \"$C_e$\",  \"$Su_{max}$\", \"Î²\",  \"$P_{max}$\",  \"$T_{lag}$\",   \"$K_f$\",   \"$K_s$\"]\n",
    "S_names = [\"Interception storage\", \"Unsaturated Rootzone Storage\", \"Fastflow storage\", \"Groundwater storage\"]\n",
    "param_names = [\"Imax\",\"Ce\",  \"Sumax\", \"beta\",  \"Pmax\",  \"Tlag\",   \"Kf\",   \"Ks\"]\n",
    "par_0 = (p_min_initial + p_max_initial)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewatercycle_wrapper_HBV import HBV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2a93492c16132434",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = HBV(forcing=ERA5_forcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f3e92bb40d31152",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "config_file, _ = model.setup(\n",
    "                            parameters=','.join([str(p) for p in par_0]),\n",
    "                            initial_storage=','.join([str(s) for s in s_0]),\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5054a44e143c71bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ewatercycle/base/model.py:168\u001b[0m, in \u001b[0;36meWaterCycleModel.initialize\u001b[0;34m(self, config_file)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize\u001b[39m(\u001b[38;5;28mself\u001b[39m, config_file: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the model.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m        config_file: Name of initialization file.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bmi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ewatercycle2/lib/python3.10/site-packages/grpc4bmi/bmi_optionaldest.py:49\u001b[0m, in \u001b[0;36mOptionalDestBmi.initialize\u001b[0;34m(self, config_file)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize\u001b[39m(\u001b[38;5;28mself\u001b[39m, config_file: Optional[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/teaching-materials/teaching-files/hbv_bmi.py:51\u001b[0m, in \u001b[0;36mHBV_Bmi.initialize\u001b[0;34m(self, config_file)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m read_config(config_file)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# store forcing & obs\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP \u001b[38;5;241m=\u001b[39m \u001b[43mload_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecipitation_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# add Tas, Tmin and Tmax support for snow component ??!\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEP \u001b[38;5;241m=\u001b[39m load_var(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpotential_evaporation_file\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpev\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/repos/teaching-materials/teaching-files/hbv_bmi.py:502\u001b[0m, in \u001b[0;36mload_var\u001b[0;34m(ncfile, varname)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_var\u001b[39m(ncfile: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Path, varname: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray:\n\u001b[1;32m    477\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load the precipitation data file generated by GenericLumpedForcing.\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \n\u001b[1;32m    479\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m        data = load_precip(forcing.directory / forcing.pr)\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mncfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdims\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m varname \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdata_vars\n",
      "File \u001b[0;32m/opt/conda/envs/ewatercycle2/lib/python3.10/site-packages/xarray/backends/api.py:553\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(backend_kwargs)\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 553\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguess_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    556\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/conda/envs/ewatercycle2/lib/python3.10/site-packages/xarray/backends/plugins.py:197\u001b[0m, in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound the following matches with the input file in xarray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms IO \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompatible_engines\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. But their dependencies may not be installed, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m     )\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html"
     ]
    }
   ],
   "source": [
    "model.initialize(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HBV' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecipitation_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/ewatercycle2/lib/python3.10/site-packages/pydantic/main.py:761\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 761\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HBV' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "model.config[\"precipitation_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0dd66560cf39beeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Q_m = []\n",
    "time = []\n",
    "while model.time < model.end_time:\n",
    "    model.update()\n",
    "    Q_m.append(model.get_value(\"Q\"))\n",
    "    time.append(pd.Timestamp(model.time_as_datetime.date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c3ee6c1849b4dd22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=Q_m,columns=[\"Modeled discharge\"],index=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the configuration file ready, we can define the model and initialize it. To clearly indicate that we are creating an instance of the class ```LeakyBucketBMI``` we use ```experiment_model``` as the name for the model object for this (demo) experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `.update()` method to advance the model one time step.\n",
    "After updating the model, we can request the current discharge using `.get_value(\"discharge\")`.\n",
    "\n",
    "We store this discharge in a list. For plotting, we also request the current model time (which is in seconds since 1970), and covert that to a pandas Timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the output discharge directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(time, discharge)\n",
    "\n",
    "plt.ylabel(f\"Discharge [{experiment_model.get_var_units('discharge')}]\")\n",
    "plt.xlabel(\"Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can also use the ```hydrograph``` function from eWaterCycle. This will make a hydrograph that compares model output to observations. For this we need to load observations and make sure that the observations and model output are in the same units. Observations typically are in m3/s. \n",
    "\n",
    "Note that the unit of discharge from this model is in mm/d. Conversion to m3/s requires the area of the catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeObject = shapereader.Reader(shapeFile.absolute())\n",
    "record = next(shapeObject.records())\n",
    "shape_area = record.attributes[\"SUB_AREA\"] * 1e6\n",
    "print(\"The catchment area is:\", shape_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hydrograph function requires dataFrames, so we put the discharge in a dataFrame and transform it to m3 per second "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_dataframe = pd.DataFrame({'model output': discharge}, index=pd.to_datetime(time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_dataframe['model output'] = discharge_dataframe['model output'] * shape_area / (1000 * 86400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation data is loaded using ```the get_grdc_data()``` function build into eWaterCycle. The observation data and discharge data are combined together into one dataFrame. Note that we re-index the discharge data to make sure they are at the same timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "observations_df, metadata = ewatercycle.observation.grdc.get_grdc_data(\n",
    "    station_id=grdc_station_id,\n",
    "    start_time=experiment_start_time,\n",
    "    end_time=experiment_end_time,\n",
    ")\n",
    "grdc_obs = observations_df.rename(columns={\"streamflow\": \"Observations from GRDC\"})\n",
    "grdc_lon = metadata[\"grdc_longitude_in_arc_degree\"]\n",
    "grdc_lat = metadata[\"grdc_latitude_in_arc_degree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_data = pd.concat([discharge_dataframe.reindex(grdc_obs.index, method = 'ffill'), grdc_obs], axis=1)\n",
    "hydro_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally plot the hydrograph. Of course the result of a simple leaky bucket model for the entire Rhine basin is a gross simplification, but it is illustrating to see that even such a simple model follows the shape of the observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hydrograph and show metrics\n",
    "ewatercycle.analysis.hydrograph(hydro_data, reference='Observations from GRDC', filename = 'experiment_hydrograph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to remove a model object when done using ```.finalize()```. For small models like this, it doesn't matter too much, but larger models that run in containers keep using resources when not ```finalized```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_model.finalize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
